# LlamaController

A WebUI-based management system for llama.cpp model lifecycle with Ollama API compatibility.

## ğŸ¯ Project Overview

LlamaController provides a secure, web-based interface to manage llama.cpp instances with full model lifecycle control (load, unload, switch) while maintaining compatibility with Ollama's REST API ecosystem. This allows existing Ollama-compatible applications to seamlessly work with llama.cpp deployments.

## âœ¨ Features

- **Centralized Model Management**: Single interface to control multiple models
- **API Compatibility**: Drop-in replacement for Ollama in existing workflows
- **Configuration Isolation**: Separate llama.cpp binaries from model configurations
- **Secure Access**: Protected by authentication with token-based API access
- **Multi-tenancy Support**: Different tokens for different applications/users
- **Web Interface**: User-friendly dashboard for model management

## ğŸ“‹ Prerequisites

- Python 3.8+ (Conda environment recommended)
- llama.cpp installed with `llama-server` executable
- GGUF model files

## ğŸš€ Quick Start

### 1. Set up Conda Environment

```powershell
# Create and activate conda environment
conda create -n llama.cpp python=3.11 -y
conda activate llama.cpp
```

### 2. Install Dependencies

```powershell
pip install -r requirements.txt
```

### 3. Configure

Copy the example configurations and edit with your paths:

```powershell
# The config files are already in config/ directory
# Edit them to match your system:
# - config/llamacpp-config.yaml
# - config/models-config.yaml
# - config/auth-config.yaml
```

### 4. Run LlamaController

```powershell
# Coming soon - main entry point
python -m src.llamacontroller.main
```

## ğŸ“ Project Structure

```
llamacontroller/
â”œâ”€â”€ src/llamacontroller/       # Main application code
â”‚   â”œâ”€â”€ core/                  # Core business logic
â”‚   â”œâ”€â”€ api/                   # REST API endpoints
â”‚   â”œâ”€â”€ auth/                  # Authentication
â”‚   â”œâ”€â”€ db/                    # Database models
â”‚   â”œâ”€â”€ web/                   # Web UI
â”‚   â”œâ”€â”€ models/                # Pydantic models
â”‚   â””â”€â”€ utils/                 # Utilities
â”œâ”€â”€ config/                    # Configuration files
â”œâ”€â”€ tests/                     # Test suite
â”œâ”€â”€ docs/                      # Documentation
â”œâ”€â”€ design/                    # Design documents
â”œâ”€â”€ scripts/                   # Utility scripts
â”œâ”€â”€ logs/                      # Application logs
â””â”€â”€ data/                      # Runtime data
```

## ğŸ”§ Development Status

This project is currently under active development.

### Phase 1: Foundation âœ… (In Progress)
- [x] Project structure
- [x] Configuration files
- [ ] Configuration manager
- [ ] llama.cpp process adapter
- [ ] Logging system

### Phase 2: Model Lifecycle ğŸ”„ (Planned)
- [ ] Model lifecycle manager
- [ ] Load/unload/switch operations

### Phase 3: API Layer ğŸ”„ (Planned)
- [ ] FastAPI application
- [ ] Ollama-compatible endpoints

### Phase 4: Authentication ğŸ”„ (Planned)
- [ ] User authentication
- [ ] API token system

### Phase 5: Web UI ğŸ”„ (Planned)
- [ ] Dashboard interface
- [ ] Token management

### Phase 6: Testing & Documentation ğŸ”„ (Planned)
- [ ] Comprehensive testing
- [ ] User documentation

## ğŸ“– Documentation

- [Project Overview](design/01-overview.md)
- [Development Setup](design/03-development-setup.md)
- [Architecture](design/04-architecture.md)
- [Implementation Guide](design/05-implementation-guide.md)

## ğŸ¤ Contributing

This project is currently in initial development. Contribution guidelines will be added soon.

## ğŸ“ License

To be determined.

## ğŸ™ Acknowledgments

- [llama.cpp](https://github.com/ggerganov/llama.cpp) - The underlying inference engine
- [Ollama](https://ollama.ai/) - API specification inspiration

---

**Status**: Development Phase  
**Version**: 0.1.0  
**Last Updated**: 2025-11-12
